<!-- Generated by SpecStory -->

# 1. run Gemma model with ollama (2025-05-31 00:14:42)

_**User**_

1. run Gemma model with ollama
2. create RESTful API Wrapper with flask
* create API key manager for API Wrapper 
* create wrapper for Oxygen Positron add-on by following:
    * https://www.oxygenxml.com/doc/ug-addons/topics/ai-positron-custom-connector.html
    * https://www.oxygenxml.com/doc/ug-addons/topics/ai_positron_enterprise.html
    * https://github.com/oxygenxml/oxygen-ai-positron-custom-connector-addon

---

_**Assistant**_

I'll help you create a complete solution for running Gemma model with Ollama and creating a RESTful API wrapper with Flask, including an API key manager and Oxygen Positron connector wrapper.

## Step-by-step Solution:

1. **Set up Ollama with Gemma model** - Install dependencies and pull the Gemma model
2. **Create Flask API wrapper** - Build a RESTful API that interfaces with Ollama
3. **Implement API key manager** - Add authentication and API key validation
4. **Create Oxygen Positron connector** - Follow the specifications to create a compatible wrapper

### [localLlmWIntelGPUV2.ipynb](file:///c%3A/Project/OCR/localLlmWIntelGPUV2.ipynb)

Add implementation for running Gemma model with Ollama and creating Flask API wrapper with API key management and Oxygen Positron connector.

````xml
<VSCode.Cell id="e4f83fd1" language="markdown">
# Local LLM with Intel GPU v2

1. run Gemma model with ollama
2. create RESTful API Wrapper with flask
* create API key manager for API Wrapper 
* create wrapper for Oxygen Positron add-on by following:
    * https://www.oxygenxml.com/doc/ug-addons/topics/ai-positron-custom-connector.html
    * https://www.oxygenxml.com/doc/ug-addons/topics/ai_positron_enterprise.html
    * https://github.com/oxygenxml/oxygen-ai-positron-custom-connector-addon
</VSCode.Cell>
<VSCode.Cell id="e7c0a448" language="python">
# Install required dependencies
import subprocess
import sys
import os
import json
import uuid
import hashlib
import time
from datetime import datetime, timedelta
from functools import wraps
from flask import Flask, request, jsonify, g
import requests
import sqlite3

# Install required packages
def install_packages():
    packages = ['flask', 'requests', 'sqlite3']
    for package in packages:
        try:
            __import__(package)
        except ImportError:
            subprocess.check_call([sys.executable, "-m", "pip", "install", package])

install_packages()

# 1. Ollama Setup and Gemma Model Management
class OllamaManager:
    def __init__(self, base_url="http://localhost:11434"):
        self.base_url = base_url
        
    def install_ollama(self):
        """Install Ollama if not already installed"""
        try:
            subprocess.run(["ollama", "--version"], check=True, capture_output=True)
            print("Ollama is already installed")
        except (subprocess.CalledProcessError, FileNotFoundError):
            print("Installing Ollama...")
            # For Windows
            if os.name == 'nt':
                print("Please download and install Ollama from: https://ollama.ai/download")
            else:
                subprocess.run(["curl", "-fsSL", "https://ollama.ai/install.sh", "|", "sh"], shell=True)
    
    def pull_gemma_model(self, model_name="gemma:2b"):
        """Pull Gemma model"""
        try:
            result = subprocess.run(["ollama", "pull", model_name], 
                                  capture_output=True, text=True, check=True)
            print(f"Successfully pulled {model_name}")
            return True
        except subprocess.CalledProcessError as e:
            print(f"Error pulling model: {e}")
            return False
    
    def list_models(self):
        """List available models"""
        try:
            result = subprocess.run(["ollama", "list"], 
                                  capture_output=True, text=True, check=True)
            return result.stdout
        except subprocess.CalledProcessError as e:
            print(f"Error listing models: {e}")
            return None
    
    def generate_response(self, prompt, model="gemma:2b", stream=False):
        """Generate response using Ollama API"""
        url = f"{self.base_url}/api/generate"
        payload = {
            "model": model,
            "prompt": prompt,
            "stream": stream
        }
        
        try:
            response = requests.post(url, json=payload)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            print(f"Error generating response: {e}")
            return None

# 2. API Key Manager
class APIKeyManager:
    def __init__(self, db_path="api_keys.db"):
        self.db_path = db_path
        self.init_database()
    
    def init_database(self):
        """Initialize SQLite database for API keys"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS api_keys (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                key_hash TEXT UNIQUE NOT NULL,
                name TEXT NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                last_used TIMESTAMP,
                is_active BOOLEAN DEFAULT 1,
                usage_count INTEGER DEFAULT 0,
                rate_limit INTEGER DEFAULT 100
            )
        ''')
        conn.commit()
        conn.close()
    
    def generate_api_key(self, name):
        """Generate a new API key"""
        api_key = f"sk-{uuid.uuid4().hex}"
        key_hash = hashlib.sha256(api_key.encode()).hexdigest()
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        try:
            cursor.execute('''
                INSERT INTO api_keys (key_hash, name) VALUES (?, ?)
            ''', (key_hash, name))
            conn.commit()
            return api_key
        except sqlite3.IntegrityError:
            return None
        finally:
            conn.close()
    
    def validate_api_key(self, api_key):
        """Validate API key and update usage"""
        key_hash = hashlib.sha256(api_key.encode()).hexdigest()
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('''
            SELECT id, is_active, usage_count, rate_limit FROM api_keys 
            WHERE key_hash = ?
        ''', (key_hash,))
        
        result = cursor.fetchone()
        if result and result[1]:  # is_active
            # Update last_used and usage_count
            cursor.execute('''
                UPDATE api_keys 
                SET last_used = CURRENT_TIMESTAMP, usage_count = usage_count + 1
                WHERE key_hash = ?
            ''', (key_hash,))
            conn.commit()
            conn.close()
            return True
        
        conn.close()
        return False

# 3. Flask API Wrapper
app = Flask(__name__)
ollama_manager = OllamaManager()
api_key_manager = APIKeyManager()

def require_api_key(f):
    """Decorator to require API key authentication"""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        api_key = request.headers.get('Authorization')
        if not api_key:
            return jsonify({'error': 'API key required'}), 401
        
        if api_key.startswith('Bearer '):
            api_key = api_key[7:]
        
        if not api_key_manager.validate_api_key(api_key):
            return jsonify({'error': 'Invalid API key'}), 401
        
        return f(*args, **kwargs)
    return decorated_function

@app.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    return jsonify({'status': 'healthy', 'timestamp': datetime.utcnow().isoformat()})

@app.route('/api/generate', methods=['POST'])
@require_api_key
def api_generate():
    """Generate text using Ollama"""
    data = request.get_json()
    
    if not data or 'prompt' not in data:
        return jsonify({'error': 'Prompt is required'}), 400
    
    prompt = data['prompt']
    model = data.get('model', 'gemma:2b')
    stream = data.get('stream', False)
    
    response = ollama_manager.generate_response(prompt, model, stream)
    
    if response:
        return jsonify(response)
    else:
        return jsonify({'error': 'Failed to generate response'}), 500

@app.route('/api/models', methods=['GET'])
@require_api_key
def api_list_models():
    """List available models"""
    models = ollama_manager.list_models()
    if models:
        return jsonify({'models': models})
    else:
        return jsonify({'error': 'Failed to list models'}), 500

@app.route('/api/keys/generate', methods=['POST'])
def generate_key():
    """Generate new API key (admin endpoint)"""
    data = request.get_json()
    if not data or 'name' not in data:
        return jsonify({'error': 'Name is required'}), 400
    
    api_key = api_key_manager.generate_api_key(data['name'])
    if api_key:
        return jsonify({'api_key': api_key})
    else:
        return jsonify({'error': 'Failed to generate API key'}), 500

# 4. Oxygen Positron Custom Connector
@app.route('/ai/chat/completions', methods=['POST'])
@require_api_key
def oxygen_chat_completions():
    """
    Oxygen Positron compatible endpoint
    Follows OpenAI Chat Completions API format
    """
    data = request.get_json()
    
    if not data or 'messages' not in data:
        return jsonify({'error': 'Messages are required'}), 400
    
    messages = data['messages']
    model = data.get('model', 'gemma:2b')
    max_tokens = data.get('max_tokens', 150)
    temperature = data.get('temperature', 0.7)
    
    # Convert messages to a single prompt
    prompt = ""
    for message in messages:
        role = message.get('role', 'user')
        content = message.get('content', '')
        if role == 'system':
            prompt += f"System: {content}\n"
        elif role == 'user':
            prompt += f"User: {content}\n"
        elif role == 'assistant':
            prompt += f"Assistant: {content}\n"
    
    prompt += "Assistant: "
    
    # Generate response using Ollama
    response = ollama_manager.generate_response(prompt, model)
    
    if response and 'response' in response:
        # Format response in OpenAI Chat Completions format
        completion_response = {
            "id": f"chatcmpl-{uuid.uuid4().hex[:8]}",
            "object": "chat.completion",
            "created": int(time.time()),
            "model": model,
            "choices": [{
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": response['response']
                },
                "finish_reason": "stop"
            }],
            "usage": {
                "prompt_tokens": len(prompt.split()),
                "completion_tokens": len(response['response'].split()),
                "total_tokens": len(prompt.split()) + len(response['response'].split())
            }
        }
        return jsonify(completion_response)
    else:
        return jsonify({'error': 'Failed to generate response'}), 500

@app.route('/ai/models', methods=['GET'])
@require_api_key
def oxygen_list_models():
    """
    Oxygen Positron compatible models endpoint
    """
    models_output = ollama_manager.list_models()
    if models_output:
        # Parse and format models for Oxygen Positron
        model_list = {
            "object": "list",
            "data": [
                {
                    "id": "gemma:2b",
                    "object": "model",
                    "created": int(time.time()),
                    "owned_by": "local"
                }
            ]
        }
        return jsonify(model_list)
    else:
        return jsonify({'error': 'Failed to list models'}), 500

# Initialize and run
if __name__ == '__main__':
    # Setup Ollama and Gemma
    print("Setting up Ollama and Gemma model...")
    ollama_manager.install_ollama()
    ollama_manager.pull_gemma_model()
    
    # Generate initial API key
    initial_key = api_key_manager.generate_api_key("default")
    print(f"Initial API Key: {initial_key}")
    print("Save this key - it won't be shown again!")
    
    # Start Flask app
    print("Starting Flask API server...")
    app.run(host='0.0.0.0', port=5000, debug=True)
</VSCode.Cell>
<VSCode.Cell language="markdown">
## Usage Instructions

### 1. Setup and Installation
- Run the notebook cell above to install dependencies and start the server
- The initial API key will be displayed - save it securely
- Ollama will be installed (if not present) and Gemma model will be pulled

### 2. API Endpoints

#### Standard Endpoints:
- `GET /health` - Health check
- `POST /api/generate` - Generate text with Ollama
- `GET /api/models` - List available models
- `POST /api/keys/generate` - Generate new API key

#### Oxygen Positron Compatible Endpoints:
- `POST /ai/chat/completions` - OpenAI-compatible chat completions
- `GET /ai/models` - OpenAI-compatible models list

### 3. Authentication
All endpoints (except health and key generation) require API key in header:
```
Authorization: Bearer your-api-key-here
```

### 4. Oxygen Positron Configuration
In Oxygen XML Author, configure the custom connector with:
- **Base URL**: `http://localhost:5000/ai`
- **API Key**: Your generated API key
- **Model**: `gemma:2b`

### 5. Example Usage
```python
import requests

headers = {'Authorization': 'Bearer your-api-key'}
data = {
    "messages": [
        {"role": "user", "content": "

---

